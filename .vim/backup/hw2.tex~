\documentclass[12pt,letterpaper]{amspset}
\usepackage[margin=1in]{geometry}
\usepackage{graphicx}
\usepackage{enumerate}
\usepackage{algorithm}
\usepackage{algorithmic}

% info for header block in upper right hand corner
\name{Zachary May}
\class{CS 515}
\assignment{Homework 2}
\duedate{Sept. 22, 2011}

\setlength{\parindent}{0cm}
\setlength{\parskip}{2ex}

\begin{document}

\problemlist{}

\begin{problem}[2.2-2]
   Consider sorting $n$ numbers stored in array $A$ by first finding the smallest element
   of $A$ and exchanging it with the element in $A[1]$ Then find the second smallest
   element of $A$, and exchange it with $A[2]$. Continue in this manner for the first $n - 1$
   elements of $A$.
   \begin{enumerate}
       \item Write pseudocode for this algorithm, which is known as \emph{selection sort}.
       \item What loop invariant does this algorithm maintain?
       \item Why does it need to run for only the first $n - 1$ elements, rather than for
             all $n$ elements?
       \item Give the best-case and worst-case running times of selection sort in
             $\Theta$-notation. 
   \end{enumerate}
\end{problem}

\begin{solution}
    \begin{algorithm}
        \caption{$\mathrm{selectionSort}(X = x_1, x_2, \cdots, x_n)$}
        \begin{algorithmic}
            \FOR{$i = 1 \to n - 1$}
                \STATE $minIndex \gets i$
                \FOR{$j = i \to n$}
                    \IF{$x_j < x_{minIndex}$} \label{algo1innercompare}
                        \STATE{$minIndex \gets j$}
                    \ENDIF
                \ENDFOR
                \IF{$i \not = minIndex$}
                    \STATE{$x_i, x_{minIndex} \gets x_{minIndex}, x_i$}
                \ENDIF
            \ENDFOR
        \end{algorithmic}
    \end{algorithm}

    (2) The outer loop maintains the invariant that the left-hand subarray (with indices less than $i$)
    is already sorted. This is trivially true initially, since the left-hand subarray is empty.
    The inner loop finds the smallest element in the right-hand subarray (with indices
    greater than or equal to $i$), the $i$th smallest element in the entire array, and puts it
    into the correct place, maintaining the invariant for the next iteration of the outer loop.

    (3) When $i = n - 1$, the invariant described in (2) ensures that $\{x_1, \cdots, x_{n-2}\}$ is sorted.
    This leaves only $x_{n-1}$ and $x_n$. If $x_{n-1} \le x_n$, there is no inversion and $X$ is sorted.
    Otherwise $x_{n} < x_{n-1}$, we swap $x_{n-1}$ with $x_{n}$ and $X$ is sorted. We never need the $n$th 
    iteration.

    (4) The best- and worst-case time complexities of selection sort are asymptotically identical,
    in $\Theta(n^2)$. In each case, the outer loop runs from 1 to $n-1$, and the inner loop from
    the outer loop index $i$ to $n$.

    In the best case, $X$ is sorted so even though the inner loop goes completely from $i$ to $n$,
    each iteration takes constant time to increment and compare the loop index plus constant time
    to perform the comparison within the inner loop. Each iteration of the outer loop takes constant
    time to increment and compare its loop index and check if a swap is needed.

    In the worst case, $X$ is in reverse order. Each iteration of the inner loop still goes from $i$
    to $n$, but we need constant additional time to update $minIndex$ at each iteration. In each
    iteration of the outer loop, we similarly need constant additional time to perform the
    swap.

    In either case, we require constant time $c_1$ for each iteration of the inner loop, plus constant
    time $c_2$ for each iteration of the outer loop. So, we have:

    \begin{eqnarray}
        \sum_{i = 1}^{n-1} [ c_1(n - i) + c_2 ] &=& c_1 n \sum_{i = 1}^{n-1} 1 - c_1 \sum_{i = 1}^{n-1} i 
                                                                               + c_2 \sum_{i = 1}^{n-1} 1     \\ \nonumber
                                            &=& c_1n(n-1) - c_1(n+1)n/2 - c_1n + c_2(n - 1)                   \\ \nonumber
                                            &=& c_1n^2 - c_1n - c_1 n^2 / 2 - c_1 n / 2 - c_1 n + c_2 n - c_2 \\ \nonumber
                                            &=& c_1n^2 / 2 - (c_2 - c_1 / 2) n - c_2                          \\ \nonumber
    \end{eqnarray}

    The $n^2$ term dominates, so selection sort runs in $\Theta(n^2)$ time in both the best and worst case.
\end{solution}

\clearpage

\begin{problem}[2.3-7]
    Describe a $\Theta(n \lg n)$-time algorithm that, given a set $S$ of $n$ integers and
    another integer $x$, determines whether or not there exist two elements in $S$ whose
    sum is exactly $x$.
\end{problem}

\begin{solution}
    Assume we have a procedure $\mathrm{sort}(X)$ that sorts an array $X = x_1, \cdots, x_n$ in time $\Theta(n \log n)$, as well 
    as a procedure $\mathrm{search}(X, k)$ that implements binary search on a sorted array $X = x_1, \cdots, x_n$, running in time
    $\Theta(\log n)$, returning a pair $(k, i)$ such that $x_i = k$ if $k \in X$, or the pair $(\mathrm{nil}, -1)$ otherwise. 

    \begin{algorithm}
        \caption{$\mathrm{findPairSum}(x, S = s_1, \cdots, s_n)$}
        \begin{algorithmic}
            \STATE{$\mathrm{sort}(S)$}
            \FOR{$i = 1 \to n$}
                \IF{$s_i \le x$}
                    \STATE{$d \gets x - s_i$}
                    \STATE{$(v, j) = \mathrm{search}(S, d)$}
                    \IF{$j \not = -1$}
                        \RETURN{$(s_i, v)$}
                    \ENDIF
                \ENDIF
            \ENDFOR
        \end{algorithmic}
    \end{algorithm}

    Each execution of $\mathrm{findPairSum}$ begins with sorting $S$, taking $\Theta(n \log n)$ time. This ensures that we can
    successfully use binary search later on.

    From there, we loop over the $n$ elements in $S$. For each element $s_i$, if it is smaller than the target $x$, we
    look for the difference $d = x - s_i$ in $S$. This is a binary search, taking $\Theta(\log n)$ time.

    So the total worst-case running time of $\mathrm{findPairSum}$ is $\Theta(n \log n) + \Theta(n \log n) = \Theta(n \log n)$.
\end{solution}

\clearpage

\begin{problem}[2-4]
    Let $A[1 .. n]$ be an array of $n$ distinct numbers. If $i < j$ and $A[i] > A[j]$, then
    the pair $(i, j)$ is called an \emph{inversion} of $A$.
    \begin{enumerate}[a.]
        \item List the five inversions of the array $\{2, 3, 8, 6, 1\}$.
        \item What array with elements from the set $\{1, 2, ..., n\}$ has the most inversions?
              How many does it have?
        \item What is the relationship between the running time of insertion sort and the 
              number of inversions in the input array?
        \item Give an algorithm that determines the number of inversions in any permutation
              on $n$ elements in $\Theta(n \lg n)$ worst-case time.
    \end{enumerate} 
\end{problem}

\begin{solution}
    \begin{enumerate}[a.]
        \item $(1, 5)$, $(2, 5)$, $(3,4)$, $(3,5)$, $(4,5)$
        \item The array $B = \{n, n-1, \cdots, 1\}$ has the most most inversions. Each element
              $B_i$ is inverted with each of the $i - 1$ elements before it. This gives a
              total number of inversions of $n(n - 1)/2$.
        \item For any input array $C = \{c_1, \cdots, c_n\}$ with $I$ inversions,
              the outer loop iterates $i$ from $1$ to $n$. At each of these iterations,
              we move $c_i$ into place within the already-sorted front part of the array
              by continually swapping $c_i$ with the element to its left if the two are
              out of order.

              By the time the outer loop terminates, any $c_k$ will have been swapped once
              for every other element it was inverted with in the original array, for a total
              of $I$ swaps. Combined with the the $n$ iterations of the outer loop, we get
              a running time in $\Theta(n + I)$ in terms of the size of the array and the
              number of inversions in it.
        \item The intuition here is to modify merge sort to track the number of inversions
              it encounters as it does its sort. Specifically, during the merge operation,
              whenever an element from the right sub-array is sent to the output array,
              we know it is inverted with all the elements in the left sub-array.
        
              See the following page for descriptions of the modified merge sort algorithm.
    \end{enumerate}
    \begin{algorithm}
        \caption{$\mathrm{countInversions}(X = x_1, \cdots, x_n)$}
        \begin{algorithmic}
            \IF{$n = 1$}
                \RETURN (X, 0)
            \ELSE
                \STATE{$mid \gets \lfloor n / 2 \rfloor$} 
                \STATE{$L \gets x_1, \cdots, x_{mid}$}
                \STATE{$R \gets x_{mid + 1}, \cdots, x_n$}
                \STATE{$L', inversions_L \gets \mathrm{countInversions}(L)$}
                \STATE{$R', inversions_R \gets \mathrm{countInversions}(R)$}
                \STATE{$X', inversions \gets \mathrm{mergeAndCount}(L', R')$}
                \RETURN{$(X', inversions + inversions_L + inversions_R)$}
            \ENDIF
        \end{algorithmic}
    \end{algorithm}
    \begin{algorithm}
        \caption{$\mathrm{mergeAndCount}(A = a_1, \cdots, a_n; B = b_1, \cdots, b_m)$}
        \begin{algorithmic}
            \STATE{Initialize $C = c_1, \cdots, c_{n+m}$}
            \STATE{$inversions \gets 0$}
            \STATE{$i, j, k \gets 1$}
            \WHILE{$i \not = n \wedge j \not = m$}
                \IF{$a_i \le b_j$}
                    \STATE{$c_k \gets a_i$}
                    \STATE{$i \gets i + 1$}
                    \STATE{$k \gets k + 1$}
                \ELSE
                    \STATE{$c_k \gets b_j$}
                    \STATE{$j \gets j + 1$}
                    \STATE{$k \gets k + 1$}
                    \STATE{$inversions \gets inversions + n - i$}
                \ENDIF
            \ENDWHILE
            \IF{$i = n$}
                \FOR{$j = j \to m$}
                    \STATE{$c_k \gets b_j$}
                    \STATE{$k \gets k + 1$}
                \ENDFOR
            \ELSE
                \FOR{$i = i \to n$}
                    \STATE{$c_k \gets a_i$}
                    \STATE{$k \gets k + 1$}
                \ENDFOR
            \ENDIF
            \RETURN{$(C, inversions)$}
        \end{algorithmic}
    \end{algorithm}
\end{solution}

\clearpage

\begin{problem}[4.4-8]
    Use a recursion tree to give an asymptotically tight solution to the recurrence
    $T(n) = T(n - a) + T(a) + cn$, where $a \ge 1$ and $c > 0$ are constants.
\end{problem}

\begin{solution}
    First, some observations about $T$:
    \begin{enumerate}
        \item $T(a)$ does not depend on $n$, so it is constant.
        \item For any $m < a$, $T(m)$ must also be constant. In particular, we note $T(n \bmod a)$
              is constant.
        \item This recurrence relation corresponds to an algorithm that makes only one
              recursive call. Each node in the recursion tree will have at most one child.
        \item Each of those recursive calls reduces the size of the sub-problem by $a$.
              Therefore, the recursion will bottom out at depth $\lfloor n / a \rfloor$.
    \end{enumerate}
    The equations below describe the non-recursive work at each level of the recursion:
    \begin{eqnarray}
        n                                         &\to&    T(a) + cn                               \\ \nonumber
        n - a                                     &\to&    T(a) + c(n - a) = T(a) + cn - ca        \\ \nonumber
        n - 2a                                    &\to&    T(a) + cn - 2ca                         \\ \nonumber
                                                  &\cdots&                                         \\ \nonumber
        n - (\lfloor n / a \rfloor - 1) a         &\to&    T(a) + cn - \lfloor n / a \rfloor ca    \\ \nonumber
        n - (\lfloor n / a \rfloor) a = n \bmod a &\to&    T(n \bmod a)                            \\ \nonumber
    \end{eqnarray}
    \begin{eqnarray}
        \sum_{i = 0}^{\lfloor n / a \rfloor} T(a) + cn + ica 
        &=&   \lfloor n / a \rfloor T(a)  + \lfloor n / a \rfloor cn + ca \sum_{i = 0}^{\lfloor n / a \rfloor} i \\ \nonumber
        &=&   \lfloor n / a \rfloor T(a)  + \lfloor n / a \rfloor cn
              + \frac{ca(\lfloor n / a \rfloor)(\lfloor n / a \rfloor)}{2} \\ \nonumber 
        &\le& \frac{T(a) n}{a} + \frac{cn^2}{a} + \frac{c^2 n^2}{2} + \frac{c^2 a}{2} \\ \nonumber
    \end{eqnarray}

    This is simply a polynomial of degree two, so $T(n) \in \Theta(n^2)$.
\end{solution}

\clearpage

\begin{problem}[4.5-4]
    Can the master method be applied to the recurrence $T(n) = 4T(n/2) + n^2\log n$?
    Why or why not? Give an asymptotic upper bound for this recurrence.
\end{problem}

\begin{solution}
    $T(n) = 4T(n/2) + n^2\log n$. Let $a = 4$, $c = 2$, $f(n) = n^2 \log n$. Note that $\log_c a = \log_2 4 = 2$.

    We can try each of the three cases of the Master theorem. 

    \begin{enumerate}
        \item $f(n) = n^2 \log n \not\in O(n^{2-\epsilon})$ for any $\epsilon > 0$ since $f(n)$ outgrows $n^2$
              even without the reduced exponent.
        \item $f(n) \not\in \Theta(n^2)$, as above.
        \item $f(n) \not\in \Omega(n^{2 + \epsilon})$ for any $\epsilon > 0$ since $\log n$ is polynomially bounded.
    \end{enumerate}

    Therefore we can't use the Master Theorem. We can however use a recursion tree to examine the non-recursive
    work done at each step and the number of recursive calls at each step. We can assume $n$ is a power of two
    to ease calculation.
    \begin{eqnarray}
        n, 1               &\to&    n^2 \log n                                                \\ \nonumber
        n/2, 4             &\to&    (n / 2)^2 \log(n / 2) = \frac{n^2}{4}(\log n - \log 2)    \\ \nonumber
        n/4, 16            &\to&    (n / 4)^2 \log(n / 4) = \frac{n^2}{16}(\log n - \log 4)   \\ \nonumber
                           &\cdots&                                                           \\ \nonumber
                           &&       r \frac{n^2}{r}(\log n - k_i)                             \\ 
    \end{eqnarray}
    At each level of the recursion tree $i$, we have (5), where $r$ is the number of recursive calls at that
    level and $k_i = \log 2^i$. So each level simplifies to $n^2 \log n - k_i n^2$. There are $\log_2 n$ levels
    in the tree, so ignoring constant factors we have:
    \[ T(n) = n^2 \log^2 n - n^2 \log n \in \Theta(n^2 \log^2 n) \]
\end{solution}

\begin{problem}[4-1c]
    Give asymptotic upper and lower bounds for $T(n) = 16T(n/4) + n^2$. Assume that $T(n)$
    is constant for $n \le 2$.
\end{problem}

\begin{solution}
    $T(n) = 16T(n/4) + n^2$. Let $a = 16$, $c = 4$, and $f(n) = n^2$. Note that $\log_c a = \log_4 16 = 2$.
    Because $f(n) = n^2 \in \Theta(n^{\log_c a}) = \Theta(n^2)$, we can apply that case of the master theorem,
    which gives $T(n) \in \Theta(n^{\log_c a}\log n) = \Theta(n^2 \log n)$.
\end{solution}

\begin{problem}[4-3b]
    Give asymptotic upper and lower bounds for $T(n) = 3T(n/3) + n / \lg n$. Assume that 
    $T(n)$ is constant for sufficiently small $n$.
\end{problem}

\begin{solution}
    We will use a recursion tree to examine the non-recursive work done at each level of recursion and the
    number of recursive calls at that level:

    \begin{eqnarray}
        n, 1              &\to&    n / \log n                                             \\ \nonumber
        n/3, 3            &\to&    (n / 3) / \log(n / 3) = \frac{n}{3(\log n - \log 3)}   \\ \nonumber
        n/9, 9            &\to&    (n / 9) / \log(n / 9) = \frac{n}{9(\log n - \log 9)}   \\ \nonumber
                          &\cdots&                                                        \\ \nonumber
                          &&       r \frac{n}{r(\log n - k_i)}                            \\ \label{41c}
    \end{eqnarray}

    At each level of the recursion tree $i$, we have \ref{41c}, where $r$ is the number of recursive
    calls at that level and $k_i = \log 3^i$. There are $\log_3 n$ levels in the tree. Also note that
    all $k_i < k = k_{\log_3 n}$, so we can simplify things a bit:
    \[ T(n) \le \frac{n \log n}{\log n - k} \le \frac{n \log n}{\log n} = n \]
    So $T(n) \in \Theta(n)$.
\end{solution}

\end{document}
